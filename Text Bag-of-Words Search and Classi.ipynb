{ 
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pplt\n",
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors  ## This guy use 1-cos_distance as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read the dataset\n",
    "df  = pd.read_csv('C:\\\\Users\\\\tanghao\\\\Desktop\\\\yelp_2k.csv',header = 0)\n",
    "docs = pd.DataFrame()\n",
    "docs['X'] = df['text'].copy()\n",
    "docs['y'] = df['stars'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove the stop words then set the max_df = 1000, min_df = 2\n",
    "vectorizer_optimized = CountVectorizer(stop_words = SW, max_df = 1000, min_df = 2)  ## Instantiate an object, \n",
    "Vec_optimized = vectorizer_optimized.fit_transform(list(docs['X']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Process the data\n",
    "X_optimized = Vec_optimized.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nearest Neighbor Method\n",
    "Neighbors = NearestNeighbors(n_neighbors = 5, metric='cosine') \n",
    "Neighbors.fit(X_optimized)  \n",
    "distance_score, index = Neighbors.kneighbors([query_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## My own split method to split it\n",
    "def trainTestSplit(dataframe, ratio):\n",
    "    random.seed(0)\n",
    "    testCount = int(len(dataframe) * (1-ratio)) + 1\n",
    "    testSampleIndex = random.sample(range(0, len(dataframe)), testCount)\n",
    "    trainSampleIndex = list(set(range(0,len(dataframe))) - set(testSampleIndex))\n",
    "    testset = dataframe.drop(trainSampleIndex)\n",
    "    trainset = dataframe.drop(testSampleIndex)\n",
    "    split1 = {}\n",
    "    split1['train'] = trainset\n",
    "    split1['test'] = testset\n",
    "    return split1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the new column with 1 or 0 for 5 stars and 1 stars\n",
    "docs['y'] = df['stars'].apply(lambda x: 1 if x == 5 else 0)  ## 'stars' is int64\n",
    "docs['X_vector'] = pd.Series(list(X_optimized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate the prediction\n",
    "LR = LogisticRegression(solver = 'lbfgs')\n",
    "LR.fit(list(vector_train),list(label_train))\n",
    "prediction_test=LR.predict(list(vector_test))\n",
    "prediction_train = LR.predict(list(vector_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The prediction rate, This is from my own method of split\n",
    "rate_test = sum(prediction_test == label_test)/len(prediction_test) ## A quick look\n",
    "rate_train = sum(prediction_train == label_train)/len(prediction_train)\n",
    "print(rate_test)\n",
    "print(rate_train)\n",
    "con_matrix_test = metrics.confusion_matrix(label_test, prediction_test)\n",
    "con_matrix_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df_train = pd.DataFrame(LR.predict_proba(list(vector_train)),columns = ['pred_0','pred_1'])\n",
    "hist_df_test = pd.DataFrame(LR.predict_proba(list(vector_test)),columns = ['pred_0','pred_1'])\n",
    "hist_df_train['label'] = pd.Series(list(label_train))\n",
    "hist_df_test['label'] = pd.Series(list(label_test))\n",
    "## get the histogram with positive label for test\n",
    "## change the threshold may improve the accuracy of test set\n",
    "fig = pplt.figure(figsize=(10,10))\n",
    "pplt.title('Histogram of Predicted Scores', fontsize = 28)\n",
    "pplt.hist(hist_df_test[hist_df_test['label'] == 0]['pred_1'],bins = 200, color = 'green', alpha = 0.5)\n",
    "pplt.hist(hist_df_test[hist_df_test['label'] == 1]['pred_1'],bins = 200, color = 'orange', alpha = 0.5)\n",
    "pplt.xlabel('Prodicted Score', fontsize = 24)\n",
    "pplt.xticks(fontsize = 18)\n",
    "pplt.ylabel('Count of prediction in bucket', fontsize = 24)\n",
    "pplt.yticks(fontsize = 18)\n",
    "pplt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
